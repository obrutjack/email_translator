#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¿»è­¯æ ¡å°èˆ‡æ½¤é£¾æ¨¡çµ„
ä½¿ç”¨å¤šç¨®å…è²»æ–¹æ¡ˆä¾†æ”¹å–„ç¿»è­¯å“è³ª
"""

import re
import requests
import json
from typing import List, Dict, Optional
import time

class TranslationProofreader:
    def __init__(self):
        """åˆå§‹åŒ–æ ¡å°å™¨"""
        self.common_errors = {
            # å°ç£ç”¨èªé¢¨æ ¼ä¿®æ­£
            "æ¶ˆæ¯": "è¨Šæ¯",  # å°ç£ç¿’æ…£ç”¨ã€Œè¨Šæ¯ã€
            "ä¿¡æ¯": "è³‡è¨Š",  # å°ç£ç¿’æ…£ç”¨ã€Œè³‡è¨Šã€
            "æ–‡ä»¶": "æª”æ¡ˆ",  # å°ç£ç¿’æ…£ç”¨ã€Œæª”æ¡ˆã€
            "è½¯ä»¶": "è»Ÿé«”",  # ç¹é«”å­—ä¿®æ­£
            "ç¡¬ä»¶": "ç¡¬é«”",  # ç¹é«”å­—ä¿®æ­£
            "ç½‘ç»œ": "ç¶²è·¯",  # å°ç£ç¿’æ…£ç”¨ã€Œç¶²è·¯ã€
            "ç½‘ç«™": "ç¶²ç«™",  # ç¹é«”å­—ä¿®æ­£
            "è®¡ç®—æœº": "é›»è…¦",  # å°ç£ç¿’æ…£ç”¨ã€Œé›»è…¦ã€
            "æ‰‹æœº": "æ‰‹æ©Ÿ",  # ç¹é«”å­—ä¿®æ­£
            "ç¨‹åº": "ç¨‹å¼",  # å°ç£ç¿’æ…£ç”¨ã€Œç¨‹å¼ã€
            "æ•°æ®": "è³‡æ–™",  # å°ç£ç¿’æ…£ç”¨ã€Œè³‡æ–™ã€
            "è§†é¢‘": "å½±ç‰‡",  # å°ç£ç¿’æ…£ç”¨ã€Œå½±ç‰‡ã€
            "éŸ³é¢‘": "éŸ³è¨Š",  # å°ç£ç¿’æ…£ç”¨ã€ŒéŸ³è¨Šã€
        }
        
        self.punctuation_fixes = {
            # æ¨™é»ç¬¦è™Ÿä¿®æ­£
            "ã€‚ã€‚": "ã€‚",
            "ï¼Ÿï¼Ÿ": "ï¼Ÿ",
            "ï¼ï¼": "ï¼",
            "ï¼Œï¼Œ": "ï¼Œ",
        }
    
    def proofread_translation(self, text: str, method: str = "multi") -> Dict[str, str]:
        """
        æ ¡å°ç¿»è­¯æ–‡æœ¬
        
        Args:
            text: éœ€è¦æ ¡å°çš„ç¿»è­¯æ–‡æœ¬
            method: æ ¡å°æ–¹æ³• ('basic', 'gemini', 'multi')
        
        Returns:
            åŒ…å«åŸæ–‡ã€æ ¡å°å¾Œæ–‡æœ¬å’Œæ”¹é€²å»ºè­°çš„å­—å…¸
        """
        result = {
            "original": text,
            "proofread": text,
            "improvements": [],
            "method_used": method
        }
        
        if method == "basic":
            result = self._basic_proofreading(result)
        elif method == "gemini":
            result = self._gemini_proofreading(result)
        elif method == "multi":
            # å…ˆåŸºæœ¬æ ¡å°ï¼Œå†ç”¨ AI æ ¡å°
            result = self._basic_proofreading(result)
            result = self._gemini_proofreading(result)
        
        return result
    
    def _basic_proofreading(self, result: Dict[str, str]) -> Dict[str, str]:
        """åŸºæœ¬æ ¡å°ï¼šä¿®æ­£å¸¸è¦‹éŒ¯èª¤å’Œæ ¼å¼å•é¡Œ"""
        text = result["proofread"]
        improvements = result["improvements"]
        
        # 1. ä¿®æ­£å¸¸è¦‹ç¿»è­¯éŒ¯èª¤
        for wrong, correct in self.common_errors.items():
            if wrong in text:
                text = text.replace(wrong, correct)
                improvements.append(f"ç”¨è©çµ±ä¸€ï¼š{wrong} â†’ {correct}")
        
        # 2. ä¿®æ­£æ¨™é»ç¬¦è™Ÿ
        for wrong, correct in self.punctuation_fixes.items():
            if wrong in text:
                text = text.replace(wrong, correct)
                improvements.append(f"æ¨™é»ä¿®æ­£ï¼š{wrong} â†’ {correct}")
        
        # 3. ç§»é™¤å¤šé¤˜ç©ºæ ¼
        original_text = text
        text = re.sub(r'\s+', ' ', text.strip())
        text = re.sub(r'\s*([ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š])\s*', r'\1', text)
        if text != original_text:
            improvements.append("ç§»é™¤å¤šé¤˜ç©ºæ ¼å’Œæ¨™é»å‰å¾Œç©ºæ ¼")
        
        # 4. ä¿®æ­£å¸¸è¦‹èªæ³•å•é¡Œ
        grammar_fixes = [
            (r'çš„çš„', 'çš„'),
            (r'äº†äº†', 'äº†'),
            (r'åœ¨åœ¨', 'åœ¨'),
            (r'æ˜¯æ˜¯', 'æ˜¯'),
        ]
        
        for pattern, replacement in grammar_fixes:
            if re.search(pattern, text):
                text = re.sub(pattern, replacement, text)
                improvements.append(f"èªæ³•ä¿®æ­£ï¼š{pattern} â†’ {replacement}")
        
        result["proofread"] = text
        result["improvements"] = improvements
        return result
    
    def _gemini_proofreading(self, result: Dict[str, str]) -> Dict[str, str]:
        """ä½¿ç”¨ Google Gemini é€²è¡Œ AI æ ¡å°"""
        try:
            # å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸æˆ–é…ç½®æª”æ¡ˆå–å¾— API Key
            import os
            api_key = os.getenv('GEMINI_API_KEY')
            
            # å¦‚æœç’°å¢ƒè®Šæ•¸æ²’æœ‰ï¼Œå˜—è©¦å¾é…ç½®æª”æ¡ˆè®€å–
            if not api_key:
                try:
                    with open('gemini_apikey.json', 'r', encoding='utf-8') as f:
                        config = json.load(f)
                        api_key = config.get('api_key')
                except FileNotFoundError:
                    pass
            
            if not api_key or api_key == "your_gemini_api_key_here":
                print("âš ï¸ æœªè¨­å®š GEMINI_API_KEYï¼Œè·³é AI æ ¡å°")
                print("ğŸ’¡ è«‹è¨­å®šç’°å¢ƒè®Šæ•¸æˆ–å»ºç«‹ gemini_apikey.json æª”æ¡ˆ")
                return result
            
            text = result["proofread"]
            
            # æ§‹å»ºæ ¡å°æç¤º
            prompt = f"""
è«‹å¹«æˆ‘æ ¡å°ä»¥ä¸‹ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼Œæ”¹å–„èªæ³•ã€ç”¨è©å’Œæµæš¢åº¦ï¼Œä½¿ç”¨å°ç£åœ°å€çš„ç”¨èªç¿’æ…£ï¼š

åŸæ–‡ï¼š
{text}

è«‹æä¾›ï¼š
1. æ ¡å°å¾Œçš„æ–‡æœ¬
2. ä¸»è¦æ”¹é€²é»

å°ç£ç”¨èªè¦æ±‚ï¼š
- ä½¿ç”¨ã€Œè³‡è¨Šã€è€Œéã€Œä¿¡æ¯ã€
- ä½¿ç”¨ã€Œè¨Šæ¯ã€è€Œéã€Œæ¶ˆæ¯ã€  
- ä½¿ç”¨ã€Œæª”æ¡ˆã€è€Œéã€Œæ–‡ä»¶ã€
- ä½¿ç”¨ã€Œè»Ÿé«”ã€è€Œéã€Œè»Ÿä»¶ã€
- ä½¿ç”¨ã€Œç¶²è·¯ã€è€Œéã€Œç¶²çµ¡ã€
- ä½¿ç”¨ã€Œé›»è…¦ã€è€Œéã€Œè¨ˆç®—æ©Ÿã€
- ä½¿ç”¨ã€Œç¨‹å¼ã€è€Œéã€Œç¨‹åºã€
- ä½¿ç”¨ã€Œè³‡æ–™ã€è€Œéã€Œæ•¸æ“šã€
- ä½¿ç”¨ã€Œå½±ç‰‡ã€è€Œéã€Œè¦–é »ã€
- ä½¿ç”¨ç¹é«”ä¸­æ–‡å­—å½¢
- èªè¨€è‡ªç„¶æµæš¢ï¼Œç¬¦åˆå°ç£äººèªªè©±ç¿’æ…£
- ä¿æŒåŸæ„ä¸è®Š

è«‹ç›´æ¥æä¾›æ ¡å°å¾Œçš„å®Œæ•´æ–‡æœ¬ï¼Œç„¶å¾Œåˆ—å‡ºä¸»è¦æ”¹é€²é»ã€‚
"""
            
            # èª¿ç”¨ Gemini API (ä½¿ç”¨æœ€æ–°æ ¼å¼)
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            data = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": 1000
                }
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                response_data = response.json()
                if 'candidates' in response_data and len(response_data['candidates']) > 0:
                    ai_response = response_data['candidates'][0]['content']['parts'][0]['text']
                    
                    # è§£æ AI å›æ‡‰
                    improved_text, improvements = self._parse_ai_response(ai_response, text)
                    
                    if improved_text and improved_text != text:
                        result["proofread"] = improved_text
                        result["improvements"].extend(improvements)
                        result["improvements"].append("AI æ ¡å°å®Œæˆ")
                    
            else:
                print(f"âš ï¸ Gemini API èª¿ç”¨å¤±æ•—: {response.status_code}")
                
        except Exception as e:
            print(f"âš ï¸ AI æ ¡å°å¤±æ•—: {e}")
        
        return result
    
    def _parse_ai_response(self, ai_response: str, original_text: str) -> tuple:
        """è§£æ AI å›æ‡‰ï¼Œæå–æ”¹é€²å¾Œçš„æ–‡æœ¬å’Œæ”¹é€²é»"""
        try:
            # ç°¡å–®çš„è§£æé‚è¼¯ï¼Œå¯ä»¥æ ¹æ“šå¯¦éš›å›æ‡‰æ ¼å¼èª¿æ•´
            lines = ai_response.strip().split('\n')
            
            improved_text = ""
            improvements = []
            
            current_section = ""
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                if "æ ¡å°å¾Œ" in line or "æ”¹é€²å¾Œ" in line:
                    current_section = "text"
                elif "æ”¹é€²é»" in line or "ä¸»è¦æ”¹é€²" in line:
                    current_section = "improvements"
                elif current_section == "text" and not line.startswith(('1.', '2.', '3.', '-', '*')):
                    if len(line) > 10:  # é¿å…æ¨™é¡Œè¡Œ
                        improved_text = line
                elif current_section == "improvements":
                    if line.startswith(('1.', '2.', '3.', '-', '*')):
                        improvements.append(line)
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºçš„æ”¹é€²æ–‡æœ¬ï¼Œå˜—è©¦æå–æœ€é•·çš„å¥å­
            if not improved_text:
                longest_line = max(lines, key=len, default="")
                if len(longest_line) > len(original_text) * 0.5:
                    improved_text = longest_line
            
            return improved_text, improvements
            
        except Exception as e:
            print(f"âš ï¸ è§£æ AI å›æ‡‰å¤±æ•—: {e}")
            return "", []
    
    def compare_translations(self, translations: List[str]) -> Dict[str, str]:
        """æ¯”è¼ƒå¤šå€‹ç¿»è­¯çµæœï¼Œé¸æ“‡æœ€ä½³ç‰ˆæœ¬"""
        if not translations:
            return {"best": "", "reason": "ç„¡ç¿»è­¯çµæœ"}
        
        if len(translations) == 1:
            return {"best": translations[0], "reason": "åƒ…æœ‰ä¸€å€‹ç¿»è­¯çµæœ"}
        
        # ç°¡å–®çš„è©•åˆ†æ©Ÿåˆ¶
        scores = []
        for trans in translations:
            score = 0
            
            # é•·åº¦åˆç†æ€§ (ä¸è¦å¤ªçŸ­æˆ–å¤ªé•·)
            length_ratio = len(trans) / max(len(t) for t in translations)
            if 0.8 <= length_ratio <= 1.2:
                score += 2
            
            # æ¨™é»ç¬¦è™Ÿä½¿ç”¨
            if re.search(r'[ï¼Œã€‚ï¼ï¼Ÿ]', trans):
                score += 1
            
            # é¿å…é‡è¤‡å­—è©
            words = list(trans)
            unique_ratio = len(set(words)) / len(words) if words else 0
            score += unique_ratio * 2
            
            # é¿å…æ˜é¡¯éŒ¯èª¤
            if not re.search(r'[â– â–¡â–ªâ–«\ufffd]', trans):
                score += 2
            
            scores.append(score)
        
        best_index = scores.index(max(scores))
        best_translation = translations[best_index]
        
        return {
            "best": best_translation,
            "reason": f"è©•åˆ†æœ€é«˜ ({max(scores):.1f}åˆ†)",
            "all_scores": dict(zip(translations, scores))
        }
    
    def enhance_translation_quality(self, original_text: str, translated_text: str) -> Dict[str, str]:
        """ç¶œåˆæå‡ç¿»è­¯å“è³ª"""
        print("ğŸ” é–‹å§‹ç¿»è­¯å“è³ªæå‡...")
        
        # åˆ†é›¢ä¸»è¦å…§å®¹å’Œé€£çµå€å¡Š
        main_content, links_section = self._separate_content_and_links(translated_text)
        
        # 1. åŸºæœ¬æ ¡å°ï¼ˆåªè™•ç†ä¸»è¦å…§å®¹ï¼‰
        result = self.proofread_translation(main_content, method="basic")
        print(f"âœ… åŸºæœ¬æ ¡å°å®Œæˆï¼Œç™¼ç¾ {len(result['improvements'])} å€‹æ”¹é€²é»")
        
        # 2. å˜—è©¦ AI æ ¡å°
        if len(main_content) < 1000:  # åªå°è¼ƒçŸ­æ–‡æœ¬ä½¿ç”¨ AI æ ¡å°
            ai_result = self.proofread_translation(result["proofread"], method="gemini")
            if len(ai_result["improvements"]) > len(result["improvements"]):
                result = ai_result
                print("âœ… AI æ ¡å°å®Œæˆ")
        
        # 3. é‡æ–°çµ„åˆå…§å®¹å’Œé€£çµ
        final_text = result["proofread"]
        if links_section:
            final_text += "\n\n" + links_section
        
        # 4. æœ€çµ‚æª¢æŸ¥
        if len(final_text) < len(translated_text) * 0.5:
            print("âš ï¸ æ ¡å°å¾Œæ–‡æœ¬éçŸ­ï¼Œä½¿ç”¨åŸç¿»è­¯")
            final_text = translated_text
            result["improvements"].append("æ ¡å°å¾Œæ–‡æœ¬ç•°å¸¸ï¼Œä¿ç•™åŸç¿»è­¯")
        
        result["proofread"] = final_text
        
        print(f"ğŸ‰ ç¿»è­¯å“è³ªæå‡å®Œæˆï¼å…± {len(result['improvements'])} å€‹æ”¹é€²")
        
        return result
    
    def _separate_content_and_links(self, text: str) -> tuple:
        """åˆ†é›¢ä¸»è¦å…§å®¹å’Œé€£çµå€å¡Š"""
        # å°‹æ‰¾é€£çµå€å¡Šçš„é–‹å§‹ä½ç½®
        link_patterns = [
            r'\n\n### ğŸ–¼ï¸ åœ–ç‰‡é€£çµ\n\n',
            r'\n\n### ğŸ“ ç›¸é—œé€£çµ\n\n'
        ]
        
        earliest_match = len(text)
        for pattern in link_patterns:
            match = re.search(pattern, text)
            if match:
                earliest_match = min(earliest_match, match.start())
        
        if earliest_match < len(text):
            # æ‰¾åˆ°é€£çµå€å¡Š
            main_content = text[:earliest_match].strip()
            links_section = text[earliest_match:].strip()
            return main_content, links_section
        else:
            # æ²’æœ‰é€£çµå€å¡Š
            return text.strip(), ""

def test_proofreader():
    """æ¸¬è©¦æ ¡å°åŠŸèƒ½"""
    proofreader = TranslationProofreader()
    
    # æ¸¬è©¦æ–‡æœ¬ï¼ˆåŒ…å«éœ€è¦ä¿®æ­£ç‚ºå°ç£ç”¨èªçš„å…§å®¹ï¼‰
    test_texts = [
        "æ‚¨å¥½ï¼Œé€™æ˜¯ä¸€å€‹æ¸¬è©¦æ¶ˆæ¯ã€‚è«‹æŸ¥çœ‹é™„ä»¶ä¸­çš„æ–‡ä»¶ã€‚ã€‚",
        "æˆ‘å€‘çš„è½¯ä»¶éœ€è¦æ›´æ–°ï¼Œè«‹æä¾›æ›´å¤šä¿¡æ¯å’Œæ•°æ®ã€‚",
        "é€™å€‹ç½‘ç»œç¨‹åºçš„çš„å•é¡Œå¾ˆé‡è¦ï¼Œæˆ‘å€‘éœ€è¦äº†äº†è§£æ›´å¤šç´°ç¯€ã€‚",
        "è«‹ä½¿ç”¨è®¡ç®—æœºæ‰“é–‹è¿™ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä¸¦æª¢æŸ¥éŸ³é¢‘å“è³ªã€‚",
        "æ–°çš„ç¡¬ä»¶å·²ç¶“å®‰è£å®Œæˆï¼Œç½‘ç«™åŠŸèƒ½æ­£å¸¸é‹ä½œã€‚"
    ]
    
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦ç¿»è­¯æ ¡å°åŠŸèƒ½...")
    print("=" * 50)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ æ¸¬è©¦ {i}:")
        print(f"åŸæ–‡: {text}")
        
        result = proofreader.proofread_translation(text, method="basic")
        
        print(f"æ ¡å°å¾Œ: {result['proofread']}")
        if result['improvements']:
            print("æ”¹é€²é»:")
            for improvement in result['improvements']:
                print(f"  - {improvement}")
        else:
            print("ç„¡éœ€æ”¹é€²")
        
        print("-" * 30)
    
    print("\nâœ… æ ¡å°åŠŸèƒ½æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    test_proofreader()